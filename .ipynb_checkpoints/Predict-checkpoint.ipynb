{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sande\\Anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sande\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from textblob import TextBlob\n",
    "from tweepy import Stream\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pprint\n",
    "import json\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from sqlalchemy import func\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np  \n",
    "import re  \n",
    "import nltk  \n",
    "from sklearn.datasets import load_files  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "nltk.download('stopwords')\n",
    "import pickle  \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"data/combined.csv\"\n",
    "df = pd.read_csv(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to combine the CVS files and then include a column 'isalive'\n",
    "# For the given date, the corresponding corresponding character will have 0 - Alive or 1 - Dead\n",
    "df[\"isalive\"] = \"\"\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"char\"] == \"Arya Stark\":\n",
    "        df.loc[index, \"isalive\"] = '0'\n",
    "    if row[\"char\"] == \"Bran Stark\":\n",
    "        df.loc[index, \"isalive\"] = '0'\n",
    "    if row[\"char\"] == \"Brienne of Tarth\":\n",
    "        df.loc[index, \"isalive\"] = '0'\n",
    "    if row[\"char\"] == \"Cersei Lannister\" :\n",
    "        if row[\"date\"] == \"05/12/2019\" \\\n",
    "            or row[\"date\"] == \"05/13/2019\" \\\n",
    "            or row[\"date\"] == \"05/14/2019\" \\\n",
    "            or row[\"date\"] == \"05/15/2019\" \\\n",
    "            or row[\"date\"] == \"05/16/2019\" \\\n",
    "            or row[\"date\"] == \"05/17/2019\":\n",
    "            df.loc[index, \"isalive\"] = '1'\n",
    "        else:\n",
    "            df.loc[index, \"isalive\"] = '0'\n",
    "    if row[\"char\"] == \"Daenerys Targaryen\":\n",
    "        df.loc[index, \"isalive\"] = '0'\n",
    "    if row[\"char\"] == \"Euron Greyjoy\":\n",
    "        if row[\"date\"] == \"05/12/2019\" \\\n",
    "            or row[\"date\"] == \"05/13/2019\" \\\n",
    "            or row[\"date\"] == \"05/14/2019\" \\\n",
    "            or row[\"date\"] == \"05/15/2019\" \\\n",
    "            or row[\"date\"] == \"05/16/2019\" \\\n",
    "            or row[\"date\"] == \"05/17/2019\":\n",
    "            df.loc[index, \"isalive\"] = '1'\n",
    "    if row[\"char\"] == \"Jaime Lannister\":\n",
    "        if row[\"date\"] == \"05/12/2019\" \\\n",
    "            or row[\"date\"] == \"05/13/2019\" \\\n",
    "            or row[\"date\"] == \"05/14/2019\" \\\n",
    "            or row[\"date\"] == \"05/15/2019\" \\\n",
    "            or row[\"date\"] == \"05/16/2019\" \\\n",
    "            or row[\"date\"] == \"05/17/2019\":\n",
    "            df.loc[index, \"isalive\"] = '1'\n",
    "    if row[\"char\"] == \"Jon Snow\":\n",
    "        df.loc[index, \"isalive\"] = '0'\n",
    "    if row[\"char\"] == \"Missandei\":\n",
    "        df.loc[index, \"isalive\"] = '0'\n",
    "    if row[\"char\"] == \"Sandor Clegane (“The Hound”)\":\n",
    "        if row[\"date\"] == \"05/12/2019\" \\\n",
    "            or row[\"date\"] == \"05/13/2019\" \\\n",
    "            or row[\"date\"] == \"05/14/2019\" \\\n",
    "            or row[\"date\"] == \"05/15/2019\" \\\n",
    "            or row[\"date\"] == \"05/16/2019\" \\\n",
    "            or row[\"date\"] == \"05/17/2019\":\n",
    "            df.loc[index, \"isalive\"] = '1'\n",
    "    if row[\"char\"] == \"Sansa Stark\":\n",
    "        df.loc[index, \"isalive\"] = '0'\n",
    "    if row[\"char\"] == \"Theon Greyjoy\":\n",
    "        if row[\"date\"] == \"05/12/2019\" \\\n",
    "            or row[\"date\"] == \"05/13/2019\" \\\n",
    "            or row[\"date\"] == \"05/14/2019\" \\\n",
    "            or row[\"date\"] == \"05/15/2019\" \\\n",
    "            or row[\"date\"] == \"05/16/2019\" \\\n",
    "            or row[\"date\"] == \"05/17/2019\":\n",
    "            df.loc[index, \"isalive\"] = '1'\n",
    "    if row[\"char\"] == \"Tyrion Lannister\":\n",
    "        df.loc[index, \"isalive\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df1 = df.loc[(df[\"date\"] == \"05/11/2019\") | (df[\"date\"] == \"05/12/2019\")]\n",
    "y = [y for y in df1[\"isalive\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for index, row in df1.iterrows():\n",
    "    x = []\n",
    "    x.append(row[\"polarity\"])\n",
    "    x.append(row[\"subjectivity\"])\n",
    "    X.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6519211682971785\n",
      "Testing Data Score: 0.6518287496455911\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df.loc[(df[\"date\"] != \"05/11/2019\") & (df[\"date\"] != \"05/12/2019\")]\n",
    "df2 = df.loc[df[\"date\"] == \"05/17/2019\"]\n",
    "new_data = []\n",
    "for index, row in df2.iterrows():\n",
    "    x = []\n",
    "    x.append(row[\"polarity\"])\n",
    "    x.append(row[\"subjectivity\"])\n",
    "    new_data.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(new_data)\n",
    "pred_df = pd.DataFrame({\"Prediction\": predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df[\"Prediction\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"text\"]\n",
    "y = df[\"isalive\"]\n",
    "\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "X = tfidfconverter.fit_transform([i for i in df[\"isalive\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = df[\"isalive\"]\n",
    "\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "X = tfidfconverter.fit_transform(df[\"polarity\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=500, random_state=0)  \n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df1[\"date\"], df1[\"polarity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "# Define the 'classDB' database in Mongo\n",
    "db = client.projDB\n",
    "char_collection = db.char_img.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_name_img_list = []\n",
    "for char in char_collection:\n",
    "    char_dict = {}\n",
    "    char_dict[\"name\"] = char[\"name\"]\n",
    "    char_dict[\"img_url\"] = char[\"img_url\"]\n",
    "    char_name_img_list.append(char_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"data/khaleesi.csv\"\n",
    "df1 = pd.read_csv(file1)\n",
    "df = df1[[\"char\", \"date\", \"polarity\"]]\n",
    "df[\"char\"] = \"Daenerys Targaryen\"    \n",
    "df2 = df.groupby([\"char\", \"date\"])[\"polarity\"].mean()\n",
    "file_df = df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df.loc[file_df[\"char\"] == \"Daenerys Targaryen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for character in char_name_img_list:\n",
    "    print (character[\"name\"])\n",
    "    char_data_df = file_df.loc[file_df[\"char\"] == character[\"name\"]]\n",
    "    print(char_data_df.size)\n",
    "    if char_data_df.size > 0:\n",
    "        character[\"date\"] = [date for date in char_data_df[\"date\"]]\n",
    "        character[\"polarity\"] = [polarity for polarity in char_data_df[\"polarity\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_name_img_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
